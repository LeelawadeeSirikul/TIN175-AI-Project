{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def create_generators(img_size = 128, datasetpath = 'dataset', batch_size = 32):\n",
    "        datagen = ImageDataGenerator(\n",
    "                             rescale = 1./255,\n",
    "                             rotation_range=30,\n",
    "                             shear_range = 0.2,\n",
    "                             zoom_range = 0.2,\n",
    "                             horizontal_flip = True)\n",
    "\n",
    "        train_generator = datagen.flow_from_directory(\n",
    "                                           datasetpath + '/' + 'training',\n",
    "                                           target_size = (img_size, img_size),\n",
    "                                           class_mode = 'categorical', \n",
    "                                           batch_size = batch_size\n",
    "                                           )\n",
    "        \n",
    "        datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "        validation_generator = datagen.flow_from_directory(\n",
    "                                            datasetpath + '/' + 'validation',\n",
    "                                            target_size = (img_size, img_size),\n",
    "                                            class_mode = 'categorical',\n",
    "                                            batch_size = batch_size\n",
    "                                            )\n",
    "        \n",
    "        test_generator = datagen.flow_from_directory(\n",
    "                                            datasetpath + '/' + 'testing',\n",
    "                                            target_size = (img_size, img_size),\n",
    "                                            class_mode = 'categorical',\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = False\n",
    "                                            )\n",
    "        \n",
    "        return train_generator, validation_generator , test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "def create_model (nb_filters = 32, nb_layers = 3, img_size = 128):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(nb_filters, (3, 3), input_shape=(img_size, img_size, 3),activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    k = 1\n",
    "    \n",
    "    for i in range (2, (nb_layers + 1)):    \n",
    "        model.add(Convolution2D(nb_filters * k, (3, 3),activation = 'relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        k = k * 2\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4,activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_graph(History, arg): #arg = acc|loss\n",
    "    plt.tight_layout()\n",
    "    plt.plot(History.history[arg])\n",
    "    val_arg = 'val_' + arg\n",
    "    plt.plot(History.history[val_arg])\n",
    "    plt.title('Model '+ arg)\n",
    "    plt.ylabel(arg)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(prediction_array):\n",
    "        prediction = prediction_array.argmax()\n",
    "        for x in train_generator.class_indices:\n",
    "            if train_generator.class_indices[x] == prediction:\n",
    "                return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://scikit-learn.org/stable/auto_examples\n",
    "#/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=8)\n",
    "\n",
    "Results = []\n",
    "\n",
    "for nb_layers in range(1,6):\n",
    "    for img_size in [64,128]: \n",
    "        for batch_size in [16,32,64]:\n",
    "            train_generator, validation_generator, test_generator = create_generators(img_size = img_size, batch_size = batch_size)\n",
    "            model = create_model(32,nb_layers,img_size = img_size)\n",
    "            History = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = len(train_generator),\n",
    "                              nb_epoch = 50,\n",
    "                              validation_data = validation_generator,\n",
    "                              validation_steps = len(validation_generator),\n",
    "                              callbacks=[early_stopping]\n",
    "                             )\n",
    "            print('\\nNumber of layers: ' + str(nb_layers) + ' ImgSize: ' + str(img_size) + ' Batch size: ' + str(batch_size) + ' :')\n",
    "            draw_graph(History, 'acc')\n",
    "            draw_graph(History, 'loss')\n",
    "            result = model.evaluate_generator(test_generator)\n",
    "            Results.append(result)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model)\n",
    "\n",
    "draw_graph(History, 'acc')\n",
    "draw_graph(History, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np \n",
    "\n",
    "def predict_flower(model = model, image_path = 'sunflower.jpg'):\n",
    "    img = image.load_img(path=image_path,target_size=(128,128,3))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    img = np.reshape(img,[1,128,128,3])\n",
    "    pred = model.predict([img])\n",
    "    return find_label(pred[0])\n",
    "\n",
    "predict_flower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_flower(model, 'tulip.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_cm_for_test(testdatapath = 'testing', img_size = 128):\n",
    "    datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    test_generator = datagen.flow_from_directory(testdatapath,\n",
    "                                            target_size = (img_size, img_size),\n",
    "                                            class_mode = 'categorical',\n",
    "                                            shuffle = False\n",
    "                                            )\n",
    "    Y_pred = model.predict_generator(test_generator, len(test_generator))\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "    plot_confusion_matrix(cm, test_generator.class_indices)\n",
    "    \n",
    "create_cm_for_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "batch_size = 32\n",
    "nb_layers = 3\n",
    "train_generator, validation_generator, test_generator = create_generators(img_size = img_size, batch_size = batch_size)\n",
    "model = create_model(32,nb_layers,img_size = img_size)\n",
    "History = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = len(train_generator),\n",
    "                              nb_epoch = 20,\n",
    "                              validation_data = validation_generator,\n",
    "                              validation_steps = len(validation_generator),\n",
    "                             )\n",
    "print('\\nNumber of layers: ' + str(nb_layers) + ' ImgSize: ' + str(img_size) + ' Batch size: ' + str(batch_size) + ' :')\n",
    "draw_graph(History, 'acc')\n",
    "draw_graph(History, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_generator(test_generator, len(test_generator))\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eval_loss, eval_accuracy) = model.evaluate_generator(test_generator, len(test_generator))\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
