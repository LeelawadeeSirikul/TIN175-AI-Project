{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datasetpath = r'C:\\Users\\SurfacePro4\\Desktop\\dataset'\n",
    "batch_size = 32\n",
    "img_size = 128\n",
    "vggmodel = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "vgg_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2197 images belonging to 4 classes.\n",
      "Found 612 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = vgg_data_gen.flow_from_directory(\n",
    "        r'C:\\Users\\SurfacePro4\\Desktop\\dataset\\training',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=False)  \n",
    "\n",
    "val_generator = vgg_data_gen.flow_from_directory(\n",
    "        r'C:\\Users\\SurfacePro4\\Desktop\\dataset\\validation',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features from train_generator (take quite long time)\n",
    "X_train = vggmodel.predict_generator(train_generator, len(train_generator))\n",
    "\n",
    "#save X_train (so we don't need to extract again)\n",
    "filename = 'cnn_features_training(i128b32)'\n",
    "with open(filename, 'wb') as f:\n",
    "          np.save(f, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features from val set\n",
    "X_val = vggmodel.predict_generator(val_generator, len(val_generator))\n",
    "filename = 'cnn_features_validation(i128b32)'\n",
    "with open(filename, 'wb') as f:\n",
    "          np.save(f, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you already have cnn_features_training/valid files, you can skip extraction cells (2 cells above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "num_classes = len(train_generator.class_indices)\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(val_generator.filenames)\n",
    "\n",
    "with open('cnn_features_training(i64b32)', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "Y_train = train_generator.classes\n",
    "Y_train = to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "with open('cnn_features_validation(i64b32)', 'rb') as f:\n",
    "    X_val = np.load(f)\n",
    "Y_val = val_generator.classes\n",
    "Y_val = to_categorical(Y_val, num_classes=num_classes)\n",
    "\n",
    "#datagen for top model (our model)\n",
    "datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#top model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/50\n",
      "2197/2197 [==============================] - 2s 888us/step - loss: 7.3276 - acc: 0.5089 - val_loss: 6.2845 - val_acc: 0.5850\n",
      "Epoch 2/50\n",
      "2197/2197 [==============================] - 1s 593us/step - loss: 6.2732 - acc: 0.5922 - val_loss: 5.8929 - val_acc: 0.6209\n",
      "Epoch 3/50\n",
      "2197/2197 [==============================] - 1s 509us/step - loss: 4.6961 - acc: 0.6796 - val_loss: 3.3377 - val_acc: 0.7614\n",
      "Epoch 4/50\n",
      "2197/2197 [==============================] - 1s 509us/step - loss: 3.6035 - acc: 0.7396 - val_loss: 3.2930 - val_acc: 0.7712\n",
      "Epoch 5/50\n",
      "2197/2197 [==============================] - 1s 555us/step - loss: 3.0652 - acc: 0.7856 - val_loss: 3.2523 - val_acc: 0.7778\n",
      "Epoch 6/50\n",
      "2197/2197 [==============================] - 1s 522us/step - loss: 2.6909 - acc: 0.8079 - val_loss: 3.2114 - val_acc: 0.7810\n",
      "Epoch 7/50\n",
      "2197/2197 [==============================] - 1s 561us/step - loss: 2.7246 - acc: 0.8084 - val_loss: 3.2586 - val_acc: 0.7696\n",
      "Epoch 8/50\n",
      "2197/2197 [==============================] - 1s 584us/step - loss: 2.6428 - acc: 0.8179 - val_loss: 3.1790 - val_acc: 0.7827\n",
      "Epoch 9/50\n",
      "2197/2197 [==============================] - 1s 616us/step - loss: 2.5168 - acc: 0.8239 - val_loss: 3.3336 - val_acc: 0.7778\n",
      "Epoch 10/50\n",
      "2197/2197 [==============================] - 1s 631us/step - loss: 2.3674 - acc: 0.8320 - val_loss: 3.4318 - val_acc: 0.7598\n",
      "Epoch 11/50\n",
      "2197/2197 [==============================] - 1s 591us/step - loss: 2.2912 - acc: 0.8375 - val_loss: 3.1597 - val_acc: 0.7892\n",
      "Epoch 12/50\n",
      "2197/2197 [==============================] - 1s 579us/step - loss: 2.0571 - acc: 0.8525 - val_loss: 3.0014 - val_acc: 0.7941\n",
      "Epoch 13/50\n",
      "2197/2197 [==============================] - 1s 523us/step - loss: 2.0954 - acc: 0.8525 - val_loss: 3.3259 - val_acc: 0.7729\n",
      "Epoch 14/50\n",
      "2197/2197 [==============================] - 1s 508us/step - loss: 1.9690 - acc: 0.8584 - val_loss: 3.0663 - val_acc: 0.7761\n",
      "Epoch 15/50\n",
      "2197/2197 [==============================] - 1s 524us/step - loss: 1.9964 - acc: 0.8612 - val_loss: 3.2456 - val_acc: 0.7614\n",
      "Epoch 16/50\n",
      "2197/2197 [==============================] - 1s 540us/step - loss: 1.8174 - acc: 0.8707 - val_loss: 3.0561 - val_acc: 0.7859\n",
      "Epoch 17/50\n",
      "2197/2197 [==============================] - 1s 622us/step - loss: 1.6811 - acc: 0.8853 - val_loss: 2.8555 - val_acc: 0.7974\n",
      "Epoch 18/50\n",
      "2197/2197 [==============================] - 1s 599us/step - loss: 1.6801 - acc: 0.8762 - val_loss: 2.8968 - val_acc: 0.7908\n",
      "Epoch 19/50\n",
      "2197/2197 [==============================] - 1s 636us/step - loss: 1.6493 - acc: 0.8803 - val_loss: 3.1980 - val_acc: 0.7729\n",
      "Epoch 20/50\n",
      "2197/2197 [==============================] - 1s 656us/step - loss: 1.6927 - acc: 0.8803 - val_loss: 2.9065 - val_acc: 0.7843\n",
      "Epoch 21/50\n",
      "2197/2197 [==============================] - 1s 643us/step - loss: 1.5140 - acc: 0.8871 - val_loss: 2.8290 - val_acc: 0.7908\n",
      "Epoch 22/50\n",
      "2197/2197 [==============================] - 2s 737us/step - loss: 1.3609 - acc: 0.9012 - val_loss: 2.7893 - val_acc: 0.7859\n",
      "Epoch 23/50\n",
      "2197/2197 [==============================] - 2s 709us/step - loss: 1.4329 - acc: 0.8926 - val_loss: 2.7280 - val_acc: 0.7941\n",
      "Epoch 24/50\n",
      "2197/2197 [==============================] - 1s 601us/step - loss: 1.3472 - acc: 0.9003 - val_loss: 2.8050 - val_acc: 0.7925\n",
      "Epoch 25/50\n",
      "2197/2197 [==============================] - 1s 538us/step - loss: 1.2933 - acc: 0.9058 - val_loss: 2.6417 - val_acc: 0.7941\n",
      "Epoch 26/50\n",
      "2197/2197 [==============================] - 1s 516us/step - loss: 1.1740 - acc: 0.9131 - val_loss: 2.6000 - val_acc: 0.8023\n",
      "Epoch 27/50\n",
      "2197/2197 [==============================] - 1s 577us/step - loss: 1.3056 - acc: 0.9044 - val_loss: 2.6435 - val_acc: 0.8121\n",
      "Epoch 28/50\n",
      "2197/2197 [==============================] - 1s 614us/step - loss: 1.1876 - acc: 0.9090 - val_loss: 2.6772 - val_acc: 0.7990\n",
      "Epoch 29/50\n",
      "2197/2197 [==============================] - 1s 602us/step - loss: 1.0948 - acc: 0.9153 - val_loss: 2.4388 - val_acc: 0.8121\n",
      "Epoch 30/50\n",
      "2197/2197 [==============================] - 1s 605us/step - loss: 0.9750 - acc: 0.9226 - val_loss: 2.5233 - val_acc: 0.8056\n",
      "Epoch 31/50\n",
      "2197/2197 [==============================] - 1s 644us/step - loss: 1.0036 - acc: 0.9203 - val_loss: 2.7416 - val_acc: 0.8007\n",
      "Epoch 32/50\n",
      "2197/2197 [==============================] - 1s 552us/step - loss: 0.9657 - acc: 0.9235 - val_loss: 2.5815 - val_acc: 0.8007\n",
      "Epoch 33/50\n",
      "2197/2197 [==============================] - 1s 540us/step - loss: 0.9070 - acc: 0.9276 - val_loss: 2.7005 - val_acc: 0.7892\n",
      "Epoch 34/50\n",
      "2197/2197 [==============================] - 1s 532us/step - loss: 0.8569 - acc: 0.9281 - val_loss: 2.5382 - val_acc: 0.8105\n",
      "Epoch 35/50\n",
      "2197/2197 [==============================] - 1s 646us/step - loss: 0.8444 - acc: 0.9299 - val_loss: 2.5453 - val_acc: 0.8088\n",
      "Epoch 36/50\n",
      "2197/2197 [==============================] - 1s 644us/step - loss: 0.8431 - acc: 0.9372 - val_loss: 2.4788 - val_acc: 0.7958\n",
      "Epoch 37/50\n",
      "2197/2197 [==============================] - 1s 608us/step - loss: 0.7900 - acc: 0.9376 - val_loss: 2.5191 - val_acc: 0.8023\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8)\n",
    "\n",
    "History = model.fit(X_train, \n",
    "                    Y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    callbacks=[early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_graph(History, arg): #arg = acc|loss\n",
    "    plt.tight_layout()\n",
    "    plt.plot(History.history[arg])\n",
    "    val_arg = 'val_' + arg\n",
    "    plt.plot(History.history[val_arg])\n",
    "    plt.title('Model '+ arg)\n",
    "    plt.ylabel(arg)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['acc'])\n",
    "plt.plot(History.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test on test set\n",
    "test_generator = vgg_data_gen.flow_from_directory(\n",
    "        r'C:\\Users\\SurfacePro4\\Desktop\\dataset\\testing',\n",
    "        target_size=(img_size, img_size),\n",
    "#         batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "cnn_features = model.predict_generator(val_generator, len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_cm_for_test(testdatapath = r'C:\\Users\\SurfacePro4\\Desktop\\dataset\\testing', img_size = 128):\n",
    "    datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    test_generator = datagen.flow_from_directory(testdatapath,\n",
    "                                            target_size = (img_size, img_size),\n",
    "                                            class_mode = 'categorical',\n",
    "                                            shuffle = False\n",
    "                                            )\n",
    "    Y_pred = model.predict_generator(test_generator, len(test_generator))\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "    plot_confusion_matrix(cm, test_generator.class_indices)\n",
    "    \n",
    "create_cm_for_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
