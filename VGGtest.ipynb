{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datasetpath = r'C:\\Users\\SurfacePro4\\Desktop\\dataset'\n",
    "batch_size = 32\n",
    "img_size = 64\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "vgg_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1759 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = vgg_data_gen.flow_from_directory(\n",
    "        r'C:\\Users\\SurfacePro4\\Desktop\\dataset\\training',\n",
    "        subset=\"training\",\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=False)  \n",
    "\n",
    "cnn_features = model.predict_generator(train_generator, len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "filename = 'cnn_features_training'\n",
    "with open(filename, 'wb') as f:\n",
    "          np.save(f, cnn_features)\n",
    "\n",
    "val_generator = vgg_data_gen.flow_from_directory(\n",
    "        r'C:\\Users\\SurfacePro4\\Desktop\\dataset\\validation',\n",
    "        subset=\"validation\",\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "cnn_features = model.predict_generator(val_generator, len(val_generator))\n",
    "filename = 'cnn_features_validation'\n",
    "with open(filename, 'wb') as f:\n",
    "          np.save(f, cnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "np.save('class_indices.npy', train_generator.class_indices)\n",
    "with open('cnn_features_training', 'rb') as f:\n",
    "    train_data = np.load(f)\n",
    "\n",
    "train_labels = train_generator.classes\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "nb_validation_samples = len(val_generator.filenames)\n",
    "\n",
    "with open('cnn_features_validation', 'rb') as f:\n",
    "    validation_data = np.load(f)\n",
    "    \n",
    "validation_labels = val_generator.classes\n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1759 samples, validate on 121 samples\n",
      "Epoch 1/50\n",
      "1759/1759 [==============================] - 3s 2ms/step - loss: 9.3767 - acc: 0.3337 - val_loss: 3.6764 - val_acc: 0.6777\n",
      "Epoch 2/50\n",
      "1759/1759 [==============================] - 1s 623us/step - loss: 6.7909 - acc: 0.4986 - val_loss: 1.6064 - val_acc: 0.8512\n",
      "Epoch 3/50\n",
      "1759/1759 [==============================] - 1s 604us/step - loss: 5.3135 - acc: 0.6049 - val_loss: 1.7668 - val_acc: 0.8430\n",
      "Epoch 4/50\n",
      "1759/1759 [==============================] - 1s 612us/step - loss: 4.5135 - acc: 0.6515 - val_loss: 2.1237 - val_acc: 0.8182\n",
      "Epoch 5/50\n",
      "1759/1759 [==============================] - 1s 626us/step - loss: 4.2374 - acc: 0.6828 - val_loss: 1.4897 - val_acc: 0.8678\n",
      "Epoch 6/50\n",
      "1759/1759 [==============================] - 1s 672us/step - loss: 4.0637 - acc: 0.6941 - val_loss: 2.5812 - val_acc: 0.8182\n",
      "Epoch 7/50\n",
      "1759/1759 [==============================] - 1s 749us/step - loss: 3.6502 - acc: 0.7203 - val_loss: 1.6512 - val_acc: 0.8512\n",
      "Epoch 8/50\n",
      "1759/1759 [==============================] - 1s 634us/step - loss: 3.0535 - acc: 0.7607 - val_loss: 1.8014 - val_acc: 0.8595\n",
      "Epoch 9/50\n",
      "1759/1759 [==============================] - 1s 637us/step - loss: 3.0081 - acc: 0.7646 - val_loss: 2.0294 - val_acc: 0.8264\n",
      "Epoch 10/50\n",
      "1759/1759 [==============================] - 1s 640us/step - loss: 3.0224 - acc: 0.7652 - val_loss: 1.5064 - val_acc: 0.8595\n",
      "Epoch 11/50\n",
      "1759/1759 [==============================] - 1s 639us/step - loss: 2.7917 - acc: 0.7726 - val_loss: 1.4994 - val_acc: 0.8678\n",
      "Epoch 12/50\n",
      "1759/1759 [==============================] - 1s 612us/step - loss: 2.4819 - acc: 0.7914 - val_loss: 1.5240 - val_acc: 0.8678\n",
      "Epoch 13/50\n",
      "1759/1759 [==============================] - 1s 636us/step - loss: 2.3478 - acc: 0.7976 - val_loss: 1.4796 - val_acc: 0.8760\n",
      "Epoch 14/50\n",
      "1759/1759 [==============================] - 1s 674us/step - loss: 2.2699 - acc: 0.7902 - val_loss: 1.5114 - val_acc: 0.8512\n",
      "Epoch 15/50\n",
      "1759/1759 [==============================] - 1s 621us/step - loss: 1.9253 - acc: 0.8158 - val_loss: 1.3982 - val_acc: 0.8430\n",
      "Epoch 16/50\n",
      "1759/1759 [==============================] - 1s 642us/step - loss: 1.8847 - acc: 0.8175 - val_loss: 1.2287 - val_acc: 0.8512\n",
      "Epoch 17/50\n",
      "1759/1759 [==============================] - 1s 632us/step - loss: 1.5321 - acc: 0.8323 - val_loss: 0.9745 - val_acc: 0.8595\n",
      "Epoch 18/50\n",
      "1759/1759 [==============================] - 1s 645us/step - loss: 1.4145 - acc: 0.8380 - val_loss: 0.9185 - val_acc: 0.8678\n",
      "Epoch 19/50\n",
      "1759/1759 [==============================] - 1s 619us/step - loss: 1.2352 - acc: 0.8476 - val_loss: 0.8963 - val_acc: 0.8926\n",
      "Epoch 20/50\n",
      "1759/1759 [==============================] - 1s 632us/step - loss: 1.0253 - acc: 0.8584 - val_loss: 0.7563 - val_acc: 0.8926\n",
      "Epoch 21/50\n",
      "1759/1759 [==============================] - 1s 633us/step - loss: 0.8995 - acc: 0.8681 - val_loss: 0.9427 - val_acc: 0.8678\n",
      "Epoch 22/50\n",
      "1759/1759 [==============================] - 1s 618us/step - loss: 0.9519 - acc: 0.8493 - val_loss: 0.7917 - val_acc: 0.8760\n",
      "Epoch 23/50\n",
      "1759/1759 [==============================] - 1s 635us/step - loss: 0.8532 - acc: 0.8675 - val_loss: 0.7316 - val_acc: 0.8678\n",
      "Epoch 24/50\n",
      "1759/1759 [==============================] - 1s 625us/step - loss: 0.7176 - acc: 0.8704 - val_loss: 0.7899 - val_acc: 0.8760\n",
      "Epoch 25/50\n",
      "1759/1759 [==============================] - 1s 626us/step - loss: 0.6208 - acc: 0.8783 - val_loss: 0.8005 - val_acc: 0.8595\n",
      "Epoch 26/50\n",
      "1759/1759 [==============================] - 1s 640us/step - loss: 0.5783 - acc: 0.8852 - val_loss: 0.6934 - val_acc: 0.8595\n",
      "Epoch 27/50\n",
      "1759/1759 [==============================] - 1s 620us/step - loss: 0.5706 - acc: 0.8823 - val_loss: 0.6711 - val_acc: 0.8926\n",
      "Epoch 28/50\n",
      "1759/1759 [==============================] - 1s 646us/step - loss: 0.5390 - acc: 0.8852 - val_loss: 0.6379 - val_acc: 0.9008\n",
      "Epoch 29/50\n",
      "1759/1759 [==============================] - 1s 623us/step - loss: 0.4497 - acc: 0.9102 - val_loss: 0.6591 - val_acc: 0.8843\n",
      "Epoch 30/50\n",
      "1759/1759 [==============================] - 1s 638us/step - loss: 0.3747 - acc: 0.9142 - val_loss: 0.5708 - val_acc: 0.9008\n",
      "Epoch 31/50\n",
      "1759/1759 [==============================] - 1s 619us/step - loss: 0.3891 - acc: 0.9005 - val_loss: 0.6405 - val_acc: 0.8843\n",
      "Epoch 32/50\n",
      "1759/1759 [==============================] - 1s 637us/step - loss: 0.3343 - acc: 0.9153 - val_loss: 0.5587 - val_acc: 0.8760\n",
      "Epoch 33/50\n",
      "1759/1759 [==============================] - 1s 638us/step - loss: 0.3215 - acc: 0.9153 - val_loss: 0.5816 - val_acc: 0.8595\n",
      "Epoch 34/50\n",
      "1759/1759 [==============================] - 1s 630us/step - loss: 0.3447 - acc: 0.9176 - val_loss: 0.5895 - val_acc: 0.8595\n",
      "Epoch 35/50\n",
      "1759/1759 [==============================] - 1s 636us/step - loss: 0.3149 - acc: 0.9255 - val_loss: 0.6133 - val_acc: 0.8512\n",
      "Epoch 36/50\n",
      "1759/1759 [==============================] - 1s 643us/step - loss: 0.2711 - acc: 0.9267 - val_loss: 0.7004 - val_acc: 0.8595\n",
      "Epoch 37/50\n",
      "1759/1759 [==============================] - 1s 645us/step - loss: 0.2882 - acc: 0.9267 - val_loss: 0.6645 - val_acc: 0.8843\n",
      "Epoch 38/50\n",
      "1759/1759 [==============================] - 1s 633us/step - loss: 0.2513 - acc: 0.9449 - val_loss: 0.7036 - val_acc: 0.8595\n",
      "Epoch 39/50\n",
      "1759/1759 [==============================] - 1s 631us/step - loss: 0.2288 - acc: 0.9323 - val_loss: 0.6219 - val_acc: 0.8760\n",
      "Epoch 40/50\n",
      "1759/1759 [==============================] - 1s 628us/step - loss: 0.2239 - acc: 0.9431 - val_loss: 0.6139 - val_acc: 0.8926\n",
      "Epoch 41/50\n",
      "1759/1759 [==============================] - 1s 654us/step - loss: 0.2469 - acc: 0.9403 - val_loss: 0.6699 - val_acc: 0.8926\n",
      "Epoch 42/50\n",
      "1759/1759 [==============================] - 1s 637us/step - loss: 0.1811 - acc: 0.9431 - val_loss: 0.6389 - val_acc: 0.8926\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=50,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels),\n",
    "                    callbacks=[early_stopping]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'testing': 0, 'training': 1, 'validation': 2}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize=32\n",
    "imgsize=64\n",
    "softmax\n",
    "3-layers (256*3)\n",
    "accuracy = 89"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
