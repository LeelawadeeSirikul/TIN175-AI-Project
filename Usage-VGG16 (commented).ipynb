{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2197 images belonging to 4 classes.\n",
      "Found 612 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define dataset path, batch size, and image size\n",
    "datasetpath = 'dataset'\n",
    "batch_size = 32\n",
    "img_size = 128\n",
    "\n",
    "#initialize VGG16 model for feature extraction\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "#ImageDataGenerator instance for train_generator\n",
    "vgg_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "#create a train_generator using data from the directory of our training set\n",
    "train_generator = vgg_data_gen.flow_from_directory(\n",
    "        datasetpath + '/' + 'training',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=False)  \n",
    "\n",
    "#extract features from the training set\n",
    "cnn_features = model.predict_generator(train_generator, len(train_generator))\n",
    "\n",
    "#save the extracted features to a file\n",
    "filename = 'cnn_features_training'\n",
    "with open(filename, 'wb') as f:\n",
    "          np.save(f, cnn_features)\n",
    "\n",
    "#apply the same thing with validation set\n",
    "val_generator = vgg_data_gen.flow_from_directory(\n",
    "        datasetpath + '/' + \"validation\",\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "cnn_features = model.predict_generator(val_generator, len(val_generator))\n",
    "filename = 'cnn_features_validation'\n",
    "with open(filename, 'wb') as f:\n",
    "          np.save(f, cnn_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw accuracy/loss graph of a given model's history\n",
    "def draw_graph(History, arg): #arg = acc|loss\n",
    "    plt.tight_layout()\n",
    "    plt.plot(History.history[arg])\n",
    "    val_arg = 'val_' + arg\n",
    "    plt.plot(History.history[val_arg])\n",
    "    plt.title('Model '+ arg)\n",
    "    plt.ylabel(arg)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['train', 'validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#get number of training samples and number of classes\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "#save class indices to a file\n",
    "np.save('class_indices.npy', train_generator.class_indices)\n",
    "\n",
    "#load extracted features of training set (like X_train)\n",
    "with open('cnn_features_training', 'rb') as f:\n",
    "    train_data = np.load(f)\n",
    "\n",
    "#get the labels of training set (like Y_train)\n",
    "train_labels = train_generator.classes\n",
    "#convert class vector to matrix (for categorical_crossentropy)\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "#get the number of samples of validation set\n",
    "nb_validation_samples = len(val_generator.filenames)\n",
    "\n",
    "#load extracted features of the validation set\n",
    "with open('cnn_features_validation', 'rb') as f:\n",
    "    validation_data = np.load(f)\n",
    "\n",
    "#prepare validation labels\n",
    "validation_labels = val_generator.classes\n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model with only 1 hidden-layer\n",
    "def create_model(nb_neurons,drop_out = 0.5):\n",
    "    #initialize a model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #add a Flatten layer and a hidden-layer\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(nb_neurons, activation='relu'))\n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    #add output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    #specify loss function, optimizer, and metrics of the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 2s 727us/step - loss: 3.8990 - acc: 0.6909 - val_loss: 2.1532 - val_acc: 0.8186\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 1s 451us/step - loss: 1.5521 - acc: 0.8635 - val_loss: 1.6955 - val_acc: 0.8399\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 1s 485us/step - loss: 1.1222 - acc: 0.8944 - val_loss: 1.5481 - val_acc: 0.8137\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 1s 477us/step - loss: 0.6405 - acc: 0.9235 - val_loss: 0.9032 - val_acc: 0.8268\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 1s 504us/step - loss: 0.3249 - acc: 0.9449 - val_loss: 1.0968 - val_acc: 0.8317\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 1s 493us/step - loss: 0.1768 - acc: 0.9645 - val_loss: 0.9665 - val_acc: 0.8513\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 1s 476us/step - loss: 0.0957 - acc: 0.9841 - val_loss: 0.9898 - val_acc: 0.8350\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 1s 476us/step - loss: 0.0870 - acc: 0.9882 - val_loss: 1.0022 - val_acc: 0.8399\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 1s 490us/step - loss: 0.0753 - acc: 0.9900 - val_loss: 1.0224 - val_acc: 0.8480\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 1s 500us/step - loss: 0.0603 - acc: 0.9932 - val_loss: 1.0002 - val_acc: 0.8464\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 1s 482us/step - loss: 0.0587 - acc: 0.9932 - val_loss: 1.0111 - val_acc: 0.8480\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 1s 475us/step - loss: 0.0581 - acc: 0.9932 - val_loss: 1.0246 - val_acc: 0.8480\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 1s 566us/step - loss: 0.0577 - acc: 0.9941 - val_loss: 1.0564 - val_acc: 0.8415\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 1s 510us/step - loss: 0.0571 - acc: 0.9945 - val_loss: 1.0720 - val_acc: 0.8448\n",
      "612/612 [==============================] - 0s 105us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 2s 977us/step - loss: 6.1099 - acc: 0.5926 - val_loss: 5.6340 - val_acc: 0.6389\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 2s 850us/step - loss: 5.3469 - acc: 0.6541 - val_loss: 5.3966 - val_acc: 0.6487\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 2s 820us/step - loss: 5.2375 - acc: 0.6668 - val_loss: 5.2702 - val_acc: 0.6618\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 2s 842us/step - loss: 5.0120 - acc: 0.6832 - val_loss: 5.3894 - val_acc: 0.6585\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 2s 843us/step - loss: 4.7915 - acc: 0.6964 - val_loss: 5.8341 - val_acc: 0.6307\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 2s 810us/step - loss: 4.7708 - acc: 0.6969 - val_loss: 5.1820 - val_acc: 0.6732\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 2s 817us/step - loss: 4.6149 - acc: 0.7082 - val_loss: 5.3769 - val_acc: 0.6569\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 2s 913us/step - loss: 4.5594 - acc: 0.7123 - val_loss: 5.3445 - val_acc: 0.660178 - acc: 0.7\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 2s 848us/step - loss: 4.7503 - acc: 0.7000 - val_loss: 5.5058 - val_acc: 0.6520\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 2s 924us/step - loss: 4.6909 - acc: 0.7046 - val_loss: 5.2275 - val_acc: 0.6683\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 2s 860us/step - loss: 4.5102 - acc: 0.7183 - val_loss: 5.1064 - val_acc: 0.6781\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 2s 836us/step - loss: 4.5423 - acc: 0.7155 - val_loss: 4.9725 - val_acc: 0.6846\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 2s 805us/step - loss: 4.3915 - acc: 0.7223 - val_loss: 4.9634 - val_acc: 0.6830\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 2s 820us/step - loss: 4.4214 - acc: 0.7219 - val_loss: 5.3216 - val_acc: 0.6634\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 2s 827us/step - loss: 4.6201 - acc: 0.7091 - val_loss: 5.1033 - val_acc: 0.6814\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 2s 881us/step - loss: 4.3850 - acc: 0.7264 - val_loss: 4.9790 - val_acc: 0.6863\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 2s 885us/step - loss: 4.3622 - acc: 0.7264 - val_loss: 5.2544 - val_acc: 0.6667\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 2s 842us/step - loss: 4.3255 - acc: 0.7292 - val_loss: 5.2905 - val_acc: 0.6667\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 2s 860us/step - loss: 4.4416 - acc: 0.7223 - val_loss: 5.0918 - val_acc: 0.6830\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 2s 829us/step - loss: 4.3271 - acc: 0.7278 - val_loss: 5.0328 - val_acc: 0.6863\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 2s 813us/step - loss: 4.3020 - acc: 0.7319 - val_loss: 4.9073 - val_acc: 0.6928\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 2s 823us/step - loss: 4.2193 - acc: 0.7365 - val_loss: 4.9882 - val_acc: 0.6863\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 2s 803us/step - loss: 4.2258 - acc: 0.7360 - val_loss: 5.0481 - val_acc: 0.6830\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 2s 841us/step - loss: 4.2646 - acc: 0.7333 - val_loss: 4.9918 - val_acc: 0.6830\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 2s 888us/step - loss: 4.2405 - acc: 0.7355 - val_loss: 4.8974 - val_acc: 0.6895\n",
      "Epoch 26/150\n",
      "2197/2197 [==============================] - 2s 852us/step - loss: 4.1837 - acc: 0.7392 - val_loss: 5.0595 - val_acc: 0.6797\n",
      "Epoch 27/150\n",
      "2197/2197 [==============================] - 2s 864us/step - loss: 4.0704 - acc: 0.7456 - val_loss: 5.1191 - val_acc: 0.6797\n",
      "Epoch 28/150\n",
      "2197/2197 [==============================] - 2s 842us/step - loss: 4.0811 - acc: 0.7460 - val_loss: 4.9132 - val_acc: 0.6944\n",
      "Epoch 29/150\n",
      "2197/2197 [==============================] - 2s 823us/step - loss: 4.1503 - acc: 0.7410 - val_loss: 5.0090 - val_acc: 0.6846\n",
      "Epoch 30/150\n",
      "2197/2197 [==============================] - 2s 815us/step - loss: 4.1469 - acc: 0.7424 - val_loss: 4.9306 - val_acc: 0.6928\n",
      "Epoch 31/150\n",
      "2197/2197 [==============================] - 2s 805us/step - loss: 4.1713 - acc: 0.7396 - val_loss: 5.0855 - val_acc: 0.6830\n",
      "Epoch 32/150\n",
      "2197/2197 [==============================] - 2s 821us/step - loss: 4.1408 - acc: 0.7410 - val_loss: 5.1342 - val_acc: 0.6797\n",
      "Epoch 33/150\n",
      "2197/2197 [==============================] - 2s 823us/step - loss: 4.2522 - acc: 0.7346 - val_loss: 4.9189 - val_acc: 0.6928\n",
      "Epoch 34/150\n",
      "2197/2197 [==============================] - 2s 882us/step - loss: 4.1041 - acc: 0.7447 - val_loss: 5.0358 - val_acc: 0.6863\n",
      "Epoch 35/150\n",
      "2197/2197 [==============================] - 2s 827us/step - loss: 4.1867 - acc: 0.7383 - val_loss: 4.7446 - val_acc: 0.7026\n",
      "Epoch 36/150\n",
      "2197/2197 [==============================] - 2s 841us/step - loss: 4.1576 - acc: 0.7410 - val_loss: 4.8088 - val_acc: 0.6993\n",
      "Epoch 37/150\n",
      "2197/2197 [==============================] - 2s 798us/step - loss: 4.0750 - acc: 0.7465 - val_loss: 4.7143 - val_acc: 0.7075\n",
      "Epoch 38/150\n",
      "2197/2197 [==============================] - 2s 800us/step - loss: 4.1932 - acc: 0.7396 - val_loss: 4.7772 - val_acc: 0.6977\n",
      "Epoch 39/150\n",
      "2197/2197 [==============================] - 2s 803us/step - loss: 4.1451 - acc: 0.7419 - val_loss: 4.9251 - val_acc: 0.6928\n",
      "Epoch 40/150\n",
      "2197/2197 [==============================] - 2s 845us/step - loss: 4.1020 - acc: 0.7451 - val_loss: 4.9876 - val_acc: 0.6879\n",
      "Epoch 41/150\n",
      "2197/2197 [==============================] - 2s 842us/step - loss: 4.2148 - acc: 0.7365 - val_loss: 5.0852 - val_acc: 0.6814\n",
      "Epoch 42/150\n",
      "2197/2197 [==============================] - 2s 845us/step - loss: 4.2658 - acc: 0.7342 - val_loss: 5.1313 - val_acc: 0.6797\n",
      "Epoch 43/150\n",
      "2197/2197 [==============================] - 2s 874us/step - loss: 4.1535 - acc: 0.7415 - val_loss: 4.9504 - val_acc: 0.6879\n",
      "Epoch 44/150\n",
      "2197/2197 [==============================] - 2s 841us/step - loss: 4.1602 - acc: 0.7401 - val_loss: 4.9918 - val_acc: 0.6879\n",
      "Epoch 45/150\n",
      "2197/2197 [==============================] - 2s 800us/step - loss: 4.0854 - acc: 0.7465 - val_loss: 5.0275 - val_acc: 0.6846\n",
      "Epoch 46/150\n",
      "2197/2197 [==============================] - 2s 859us/step - loss: 4.0882 - acc: 0.7460 - val_loss: 4.9530 - val_acc: 0.6879\n",
      "Epoch 47/150\n",
      "2197/2197 [==============================] - 2s 841us/step - loss: 4.0699 - acc: 0.7474 - val_loss: 5.1982 - val_acc: 0.6765\n",
      "612/612 [==============================] - 0s 156us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 8.4360 - acc: 0.4665 - val_loss: 8.2822 - val_acc: 0.4820\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 8.5459 - acc: 0.4675 - val_loss: 8.7748 - val_acc: 0.4526\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 8.3030 - acc: 0.4820 - val_loss: 8.1319 - val_acc: 0.4918\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.2091 - acc: 0.4884 - val_loss: 8.1754 - val_acc: 0.4902\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.0248 - acc: 0.5007 - val_loss: 8.1844 - val_acc: 0.4902\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.9630 - acc: 0.5048 - val_loss: 8.2049 - val_acc: 0.4886\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 7.9730 - acc: 0.5043 - val_loss: 8.0541 - val_acc: 0.4984\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 7.8934 - acc: 0.5089 - val_loss: 8.0693 - val_acc: 0.4967\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.8825 - acc: 0.5102 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.9726 - acc: 0.5048 - val_loss: 8.0327 - val_acc: 0.5016\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.8977 - acc: 0.5098 - val_loss: 8.0854 - val_acc: 0.4984\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 7.9414 - acc: 0.5071 - val_loss: 8.0859 - val_acc: 0.4984\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.9539 - acc: 0.5061 - val_loss: 8.0820 - val_acc: 0.4984\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.8716 - acc: 0.5112 - val_loss: 8.0596 - val_acc: 0.5000\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.8791 - acc: 0.5107 - val_loss: 8.0881 - val_acc: 0.4967\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.8619 - acc: 0.5112 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 7.8652 - acc: 0.5116 - val_loss: 7.9507 - val_acc: 0.5033\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.9033 - acc: 0.5093 - val_loss: 7.9942 - val_acc: 0.5033\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.2776 - acc: 0.4861 - val_loss: 8.4084 - val_acc: 0.4771\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.2902 - acc: 0.4857 - val_loss: 8.3224 - val_acc: 0.4837\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.9945 - acc: 0.5039 - val_loss: 8.1588 - val_acc: 0.4935\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 7.9219 - acc: 0.5084 - val_loss: 8.1117 - val_acc: 0.4967\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.0349 - acc: 0.5007 - val_loss: 8.0854 - val_acc: 0.4984\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.1701 - acc: 0.4929 - val_loss: 8.4014 - val_acc: 0.4788\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.1196 - acc: 0.4961 - val_loss: 7.9988 - val_acc: 0.5033\n",
      "Epoch 26/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 7.8362 - acc: 0.5134 - val_loss: 8.3437 - val_acc: 0.4804\n",
      "Epoch 27/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 7.9817 - acc: 0.5043 - val_loss: 8.1117 - val_acc: 0.4967\n",
      "612/612 [==============================] - 0s 160us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 2s 834us/step - loss: 4.6123 - acc: 0.6436 - val_loss: 2.4844 - val_acc: 0.7843\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 1s 491us/step - loss: 1.7349 - acc: 0.8125 - val_loss: 1.2415 - val_acc: 0.8088\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 1s 480us/step - loss: 0.7692 - acc: 0.8639 - val_loss: 0.9656 - val_acc: 0.8186\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 1s 499us/step - loss: 0.4925 - acc: 0.8675 - val_loss: 0.6697 - val_acc: 0.8333\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 1s 473us/step - loss: 0.3396 - acc: 0.8980 - val_loss: 0.7534 - val_acc: 0.8448\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 1s 490us/step - loss: 0.3027 - acc: 0.9149 - val_loss: 0.6319 - val_acc: 0.8529\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 1s 482us/step - loss: 0.2599 - acc: 0.9235 - val_loss: 0.7406 - val_acc: 0.8529\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 1s 475us/step - loss: 0.1707 - acc: 0.9463 - val_loss: 0.8475 - val_acc: 0.8350\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 1s 480us/step - loss: 0.1728 - acc: 0.9490 - val_loss: 1.0131 - val_acc: 0.8350\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 1s 479us/step - loss: 0.1854 - acc: 0.9499 - val_loss: 0.8163 - val_acc: 0.8415\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 1s 509us/step - loss: 0.1444 - acc: 0.9563 - val_loss: 0.9426 - val_acc: 0.8595\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 1s 598us/step - loss: 0.1305 - acc: 0.9645 - val_loss: 0.8988 - val_acc: 0.8546\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 1s 511us/step - loss: 0.1217 - acc: 0.9654 - val_loss: 0.9587 - val_acc: 0.8415\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 1s 483us/step - loss: 0.1124 - acc: 0.9650 - val_loss: 1.1122 - val_acc: 0.8366\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 1s 512us/step - loss: 0.1039 - acc: 0.9659 - val_loss: 0.9190 - val_acc: 0.8529\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 1s 496us/step - loss: 0.1182 - acc: 0.9659 - val_loss: 1.0773 - val_acc: 0.8415\n",
      "612/612 [==============================] - 0s 126us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 2s 1ms/step - loss: 6.8083 - acc: 0.5471 - val_loss: 5.1682 - val_acc: 0.6601\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 2s 839us/step - loss: 3.8422 - acc: 0.7301 - val_loss: 2.7570 - val_acc: 0.7974\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 2s 866us/step - loss: 2.4729 - acc: 0.8229 - val_loss: 2.4193 - val_acc: 0.8301\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 2s 850us/step - loss: 2.1070 - acc: 0.8498 - val_loss: 2.4018 - val_acc: 0.8219\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 2s 869us/step - loss: 1.9081 - acc: 0.8616 - val_loss: 2.0408 - val_acc: 0.8546\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 2s 945us/step - loss: 1.6008 - acc: 0.8803 - val_loss: 2.2101 - val_acc: 0.8399\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 2s 839us/step - loss: 1.4399 - acc: 0.8999 - val_loss: 2.0737 - val_acc: 0.8578\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 2s 841us/step - loss: 1.3775 - acc: 0.9003 - val_loss: 2.0321 - val_acc: 0.8562\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 2s 848us/step - loss: 1.4569 - acc: 0.8967 - val_loss: 1.9426 - val_acc: 0.8562\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 2s 823us/step - loss: 1.2576 - acc: 0.9122 - val_loss: 2.5732 - val_acc: 0.8219\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 2s 820us/step - loss: 1.0997 - acc: 0.9194 - val_loss: 2.1073 - val_acc: 0.8562\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 2s 872us/step - loss: 0.9531 - acc: 0.9335 - val_loss: 2.0106 - val_acc: 0.8595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 2s 872us/step - loss: 0.9074 - acc: 0.9386 - val_loss: 2.0629 - val_acc: 0.8595\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 2s 882us/step - loss: 0.8239 - acc: 0.9413 - val_loss: 2.2654 - val_acc: 0.8464\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 2s 840us/step - loss: 0.8213 - acc: 0.9390 - val_loss: 2.0134 - val_acc: 0.8611\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 2s 848us/step - loss: 0.8109 - acc: 0.9417 - val_loss: 2.3084 - val_acc: 0.8448\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 2s 833us/step - loss: 0.8201 - acc: 0.9445 - val_loss: 1.8451 - val_acc: 0.8693\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 2s 827us/step - loss: 0.7847 - acc: 0.9431 - val_loss: 1.9330 - val_acc: 0.8676\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 2s 821us/step - loss: 0.6877 - acc: 0.9499 - val_loss: 2.0350 - val_acc: 0.8595\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 2s 823us/step - loss: 0.7027 - acc: 0.9531 - val_loss: 2.0214 - val_acc: 0.8529\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 2s 840us/step - loss: 0.8408 - acc: 0.9436 - val_loss: 2.3971 - val_acc: 0.8317\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 2s 815us/step - loss: 0.7002 - acc: 0.9513 - val_loss: 2.1681 - val_acc: 0.8480\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 2s 885us/step - loss: 0.5775 - acc: 0.9568 - val_loss: 1.9099 - val_acc: 0.8627\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 2s 834us/step - loss: 0.5744 - acc: 0.9590 - val_loss: 2.0637 - val_acc: 0.8595\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 2s 834us/step - loss: 0.5739 - acc: 0.9636 - val_loss: 1.9257 - val_acc: 0.8660\n",
      "Epoch 26/150\n",
      "2197/2197 [==============================] - 2s 786us/step - loss: 0.5983 - acc: 0.9595 - val_loss: 2.0196 - val_acc: 0.8627\n",
      "Epoch 27/150\n",
      "2197/2197 [==============================] - 2s 815us/step - loss: 0.5829 - acc: 0.9604 - val_loss: 2.0143 - val_acc: 0.8644\n",
      "612/612 [==============================] - 0s 155us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 6.6944 - acc: 0.5599 - val_loss: 5.3561 - val_acc: 0.6585\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 5.6577 - acc: 0.6404 - val_loss: 5.0738 - val_acc: 0.6781\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 5.5846 - acc: 0.6450 - val_loss: 5.6577 - val_acc: 0.6422TA: 0s - loss: 5.6184 - acc: 0.64\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 5.2516 - acc: 0.6673 - val_loss: 5.2321 - val_acc: 0.6667\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 5.3822 - acc: 0.6586 - val_loss: 4.9825 - val_acc: 0.6879\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 5.1334 - acc: 0.6759 - val_loss: 4.8400 - val_acc: 0.6961\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 4.9871 - acc: 0.6855 - val_loss: 4.7257 - val_acc: 0.7026\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 5.1085 - acc: 0.6791 - val_loss: 5.4336 - val_acc: 0.6585\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 5.0866 - acc: 0.6818 - val_loss: 5.2147 - val_acc: 0.6748\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 5.0394 - acc: 0.6846 - val_loss: 4.9765 - val_acc: 0.6846\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 4.8735 - acc: 0.6959 - val_loss: 4.8905 - val_acc: 0.6944\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 4.7255 - acc: 0.7032 - val_loss: 5.2347 - val_acc: 0.6732\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 4.8404 - acc: 0.6959 - val_loss: 5.2289 - val_acc: 0.6732\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 4.6705 - acc: 0.7060 - val_loss: 5.0777 - val_acc: 0.6797\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 4.7021 - acc: 0.7060 - val_loss: 4.9428 - val_acc: 0.6928\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 4.6945 - acc: 0.7060 - val_loss: 5.6689 - val_acc: 0.6454\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 4.8772 - acc: 0.6946 - val_loss: 5.2224 - val_acc: 0.6716\n",
      "612/612 [==============================] - 0s 155us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 2s 732us/step - loss: 6.3847 - acc: 0.5412 - val_loss: 3.9290 - val_acc: 0.7010\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 1s 498us/step - loss: 2.2354 - acc: 0.7333 - val_loss: 0.8646 - val_acc: 0.8023\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 1s 480us/step - loss: 0.9407 - acc: 0.7255 - val_loss: 0.7687 - val_acc: 0.7418\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 1s 500us/step - loss: 0.7457 - acc: 0.7237 - val_loss: 0.7254 - val_acc: 0.8219\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 1s 501us/step - loss: 0.6703 - acc: 0.7724 - val_loss: 0.6433 - val_acc: 0.8252\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 1s 496us/step - loss: 0.5843 - acc: 0.7997 - val_loss: 0.6569 - val_acc: 0.8235\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 1s 497us/step - loss: 0.5798 - acc: 0.8147 - val_loss: 0.6476 - val_acc: 0.8203\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 1s 483us/step - loss: 0.5138 - acc: 0.8261 - val_loss: 0.7699 - val_acc: 0.8170\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 1s 507us/step - loss: 0.4670 - acc: 0.8320 - val_loss: 0.6954 - val_acc: 0.8480\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 1s 486us/step - loss: 0.4239 - acc: 0.8384 - val_loss: 0.8725 - val_acc: 0.8464\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 1s 501us/step - loss: 0.4177 - acc: 0.8471 - val_loss: 0.6859 - val_acc: 0.8448\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 1s 528us/step - loss: 0.4423 - acc: 0.8525 - val_loss: 0.8942 - val_acc: 0.8170\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 1s 552us/step - loss: 0.3890 - acc: 0.8466 - val_loss: 0.7825 - val_acc: 0.8431\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 1s 517us/step - loss: 0.3680 - acc: 0.8603 - val_loss: 0.6268 - val_acc: 0.8627\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 1s 494us/step - loss: 0.3397 - acc: 0.8698 - val_loss: 0.7843 - val_acc: 0.8595\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 1s 496us/step - loss: 0.4015 - acc: 0.8739 - val_loss: 0.7698 - val_acc: 0.8529\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 1s 479us/step - loss: 0.3563 - acc: 0.8871 - val_loss: 0.6138 - val_acc: 0.8611\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 1s 492us/step - loss: 0.3293 - acc: 0.8694 - val_loss: 0.6080 - val_acc: 0.8725\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 1s 496us/step - loss: 0.3258 - acc: 0.8785 - val_loss: 0.5988 - val_acc: 0.8676\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 1s 491us/step - loss: 0.3153 - acc: 0.8858 - val_loss: 0.7305 - val_acc: 0.8529\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 1s 490us/step - loss: 0.3176 - acc: 0.8748 - val_loss: 0.6550 - val_acc: 0.8611\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 1s 510us/step - loss: 0.2670 - acc: 0.9012 - val_loss: 0.6543 - val_acc: 0.8676\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 1s 507us/step - loss: 0.2964 - acc: 0.8953 - val_loss: 0.7170 - val_acc: 0.8644\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 1s 481us/step - loss: 0.2930 - acc: 0.8903 - val_loss: 0.7804 - val_acc: 0.8595\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 1s 495us/step - loss: 0.2900 - acc: 0.8944 - val_loss: 0.8635 - val_acc: 0.8595\n",
      "Epoch 26/150\n",
      "2197/2197 [==============================] - 1s 484us/step - loss: 0.3777 - acc: 0.8894 - val_loss: 0.8959 - val_acc: 0.8742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "2197/2197 [==============================] - 1s 573us/step - loss: 0.2873 - acc: 0.8985 - val_loss: 0.7665 - val_acc: 0.8578\n",
      "Epoch 28/150\n",
      "2197/2197 [==============================] - 1s 552us/step - loss: 0.3229 - acc: 0.8967 - val_loss: 0.8007 - val_acc: 0.8611\n",
      "Epoch 29/150\n",
      "2197/2197 [==============================] - 1s 473us/step - loss: 0.3131 - acc: 0.9076 - val_loss: 0.7892 - val_acc: 0.8742\n",
      "612/612 [==============================] - 0s 120us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 2s 1ms/step - loss: 5.5428 - acc: 0.6136 - val_loss: 2.8614 - val_acc: 0.7892\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 2s 810us/step - loss: 3.4063 - acc: 0.7569 - val_loss: 2.1394 - val_acc: 0.8301\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 2s 837us/step - loss: 2.8225 - acc: 0.7970 - val_loss: 2.5081 - val_acc: 0.8203\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 2s 817us/step - loss: 2.6017 - acc: 0.8111 - val_loss: 1.8565 - val_acc: 0.8595\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 2s 857us/step - loss: 2.2187 - acc: 0.8448 - val_loss: 2.4554 - val_acc: 0.8219\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 2s 837us/step - loss: 2.0533 - acc: 0.8516 - val_loss: 1.9083 - val_acc: 0.8595\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 2s 905us/step - loss: 1.9703 - acc: 0.8598 - val_loss: 2.3957 - val_acc: 0.8317\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 2s 838us/step - loss: 1.8264 - acc: 0.8671 - val_loss: 2.0977 - val_acc: 0.8513\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 2s 856us/step - loss: 1.8409 - acc: 0.8675 - val_loss: 1.8900 - val_acc: 0.8693\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 2s 843us/step - loss: 1.6282 - acc: 0.8826 - val_loss: 2.1399 - val_acc: 0.8497\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 2s 869us/step - loss: 1.5571 - acc: 0.8889 - val_loss: 1.9482 - val_acc: 0.8693\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 2s 890us/step - loss: 1.4253 - acc: 0.8953 - val_loss: 1.8420 - val_acc: 0.8611\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 2s 836us/step - loss: 1.4077 - acc: 0.8971 - val_loss: 2.0451 - val_acc: 0.8546\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 2s 819us/step - loss: 1.1989 - acc: 0.9108 - val_loss: 1.9046 - val_acc: 0.8562\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 2s 861us/step - loss: 1.1388 - acc: 0.9153 - val_loss: 1.6395 - val_acc: 0.8807\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 2s 900us/step - loss: 1.2227 - acc: 0.9103 - val_loss: 1.9456 - val_acc: 0.8578\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 2s 852us/step - loss: 1.2191 - acc: 0.9099 - val_loss: 2.0020 - val_acc: 0.8529\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 2s 897us/step - loss: 1.0929 - acc: 0.9194 - val_loss: 1.6911 - val_acc: 0.8807\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 2s 881us/step - loss: 1.0035 - acc: 0.9244 - val_loss: 1.7732 - val_acc: 0.8742\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 2s 875us/step - loss: 0.9531 - acc: 0.9276 - val_loss: 1.5212 - val_acc: 0.8905\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 2s 835us/step - loss: 0.9309 - acc: 0.9349 - val_loss: 1.6306 - val_acc: 0.8775\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 2s 849us/step - loss: 1.0448 - acc: 0.9235 - val_loss: 1.7422 - val_acc: 0.8693\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 2s 799us/step - loss: 0.9658 - acc: 0.9313 - val_loss: 1.6828 - val_acc: 0.8758\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 2s 905us/step - loss: 0.9609 - acc: 0.9290 - val_loss: 1.8315 - val_acc: 0.8595\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 2s 820us/step - loss: 0.7998 - acc: 0.9408 - val_loss: 1.4208 - val_acc: 0.8987\n",
      "Epoch 26/150\n",
      "2197/2197 [==============================] - 2s 817us/step - loss: 0.8423 - acc: 0.9367 - val_loss: 1.4545 - val_acc: 0.8905\n",
      "Epoch 27/150\n",
      "2197/2197 [==============================] - 2s 836us/step - loss: 0.7540 - acc: 0.9445 - val_loss: 1.5801 - val_acc: 0.8840\n",
      "Epoch 28/150\n",
      "2197/2197 [==============================] - 2s 844us/step - loss: 0.8123 - acc: 0.9395 - val_loss: 1.7873 - val_acc: 0.8742\n",
      "Epoch 29/150\n",
      "2197/2197 [==============================] - 2s 847us/step - loss: 0.6429 - acc: 0.9495 - val_loss: 1.7860 - val_acc: 0.8791\n",
      "Epoch 30/150\n",
      "2197/2197 [==============================] - 2s 839us/step - loss: 0.6568 - acc: 0.9477 - val_loss: 1.6263 - val_acc: 0.8791\n",
      "Epoch 31/150\n",
      "2197/2197 [==============================] - 2s 829us/step - loss: 0.7492 - acc: 0.9431 - val_loss: 1.6556 - val_acc: 0.8725\n",
      "Epoch 32/150\n",
      "2197/2197 [==============================] - 2s 843us/step - loss: 0.6958 - acc: 0.9449 - val_loss: 1.8588 - val_acc: 0.8627\n",
      "Epoch 33/150\n",
      "2197/2197 [==============================] - 2s 914us/step - loss: 0.7379 - acc: 0.9422 - val_loss: 1.6253 - val_acc: 0.8742\n",
      "Epoch 34/150\n",
      "2197/2197 [==============================] - 2s 827us/step - loss: 0.5634 - acc: 0.9554 - val_loss: 1.5193 - val_acc: 0.8824\n",
      "Epoch 35/150\n",
      "2197/2197 [==============================] - 2s 841us/step - loss: 0.6013 - acc: 0.9495 - val_loss: 1.6416 - val_acc: 0.8725\n",
      "612/612 [==============================] - 0s 152us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 6.6394 - acc: 0.5644 - val_loss: 5.3171 - val_acc: 0.6503\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 6.0331 - acc: 0.6140 - val_loss: 5.9632 - val_acc: 0.6193\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 5.7300 - acc: 0.6363 - val_loss: 5.3843 - val_acc: 0.6552\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 5.3094 - acc: 0.6623 - val_loss: 5.3223 - val_acc: 0.6650\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 4.6837 - acc: 0.7005 - val_loss: 3.6669 - val_acc: 0.7549\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 3.5447 - acc: 0.7679 - val_loss: 2.8994 - val_acc: 0.8137\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.9715 - acc: 0.8102 - val_loss: 2.7669 - val_acc: 0.8219\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 3.0735 - acc: 0.8029 - val_loss: 2.8953 - val_acc: 0.8137\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 3.3540 - acc: 0.7833 - val_loss: 3.5057 - val_acc: 0.7745\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.6785 - acc: 0.8257 - val_loss: 2.7448 - val_acc: 0.8219\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.5950 - acc: 0.8352 - val_loss: 2.7542 - val_acc: 0.8252\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.8728 - acc: 0.8170 - val_loss: 3.1457 - val_acc: 0.7925\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.6566 - acc: 0.8298 - val_loss: 2.7663 - val_acc: 0.8252\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.6435 - acc: 0.8311 - val_loss: 2.4294 - val_acc: 0.8448\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.3139 - acc: 0.8521 - val_loss: 1.9799 - val_acc: 0.8709\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.3642 - acc: 0.8489 - val_loss: 2.6779 - val_acc: 0.8301\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.2471 - acc: 0.8557 - val_loss: 2.2817 - val_acc: 0.8546\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.2222 - acc: 0.8580 - val_loss: 2.7674 - val_acc: 0.8252\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.1932 - acc: 0.8571 - val_loss: 2.1937 - val_acc: 0.8611\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.9733 - acc: 0.8735 - val_loss: 2.5488 - val_acc: 0.8366\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.2904 - acc: 0.8543 - val_loss: 2.7524 - val_acc: 0.8235\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.0792 - acc: 0.8671 - val_loss: 2.6473 - val_acc: 0.8284\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.0270 - acc: 0.8703 - val_loss: 2.7399 - val_acc: 0.8284\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.1970 - acc: 0.8607 - val_loss: 2.6618 - val_acc: 0.8317\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.1623 - acc: 0.8616 - val_loss: 2.6181 - val_acc: 0.8333\n",
      "612/612 [==============================] - 0s 174us/step\n"
     ]
    }
   ],
   "source": [
    "#initialize array of results\n",
    "Result = []\n",
    "\n",
    "#apply grid-search-like loops to try multiple combinations of hyperparameters\n",
    "for drop_out in [0,0.25,0.5]:\n",
    "    for nb_neurons in [64,128,256]:\n",
    "        #create model\n",
    "        model = create_model(nb_neurons, drop_out)\n",
    "        #apply early_stopping to prevent overfitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "        #train the model\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                            epochs=150,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_data=(validation_data, validation_labels),\n",
    "                            callbacks=[early_stopping]\n",
    "                            )\n",
    "        #evaluate model on the validation set\n",
    "        result = model.evaluate(validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "        #save the result in the array\n",
    "        Result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model with 2 hidden-layers\n",
    "def create_model2(nb_neurons,drop_out = 0.5):\n",
    "    #initialize a model\n",
    "    model = Sequential()\n",
    "    #add a Flatten layer and 2 hidden-layers\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(nb_neurons, activation='relu'))\n",
    "    model.add(Dropout(drop_out))\n",
    "    model.add(Dense(nb_neurons//2, activation='relu'))\n",
    "    model.add(Dropout(drop_out))\n",
    "    #add output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    #specify loss function, optimizer, and metrics of the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 2s 1ms/step - loss: 3.4407 - acc: 0.6946 - val_loss: 1.9917 - val_acc: 0.7941\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 2s 838us/step - loss: 1.3228 - acc: 0.8598 - val_loss: 1.8225 - val_acc: 0.7974\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 2s 845us/step - loss: 0.8221 - acc: 0.9058 - val_loss: 1.4569 - val_acc: 0.8366\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 2s 940us/step - loss: 0.4712 - acc: 0.9508 - val_loss: 1.8011 - val_acc: 0.7908\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 2s 862us/step - loss: 0.3529 - acc: 0.9604 - val_loss: 1.3973 - val_acc: 0.8529\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 2s 842us/step - loss: 0.3517 - acc: 0.9663 - val_loss: 1.6031 - val_acc: 0.8464\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 2s 831us/step - loss: 0.2448 - acc: 0.9727 - val_loss: 1.4593 - val_acc: 0.8366\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 2s 831us/step - loss: 0.2038 - acc: 0.9822 - val_loss: 1.4701 - val_acc: 0.8415\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 2s 831us/step - loss: 0.1464 - acc: 0.9863 - val_loss: 1.1891 - val_acc: 0.8448\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 2s 817us/step - loss: 0.1353 - acc: 0.9891 - val_loss: 1.1358 - val_acc: 0.8660\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 2s 831us/step - loss: 0.1197 - acc: 0.9918 - val_loss: 1.0424 - val_acc: 0.8660\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 2s 948us/step - loss: 0.1248 - acc: 0.9914 - val_loss: 1.2055 - val_acc: 0.8611\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 2s 898us/step - loss: 0.1209 - acc: 0.9914 - val_loss: 1.1355 - val_acc: 0.8595\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 2s 882us/step - loss: 0.1175 - acc: 0.9927 - val_loss: 1.1299 - val_acc: 0.8627\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 2s 837us/step - loss: 0.1175 - acc: 0.9927 - val_loss: 1.1291 - val_acc: 0.8627\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 2s 828us/step - loss: 0.1175 - acc: 0.9927 - val_loss: 1.1275 - val_acc: 0.8627\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 2s 819us/step - loss: 0.1174 - acc: 0.9927 - val_loss: 1.1274 - val_acc: 0.8627\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 2s 819us/step - loss: 0.1174 - acc: 0.9927 - val_loss: 1.1274 - val_acc: 0.8627\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 2s 828us/step - loss: 0.1174 - acc: 0.9927 - val_loss: 1.1275 - val_acc: 0.8627\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 2s 864us/step - loss: 0.1174 - acc: 0.9927 - val_loss: 1.1276 - val_acc: 0.8627\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 2s 960us/step - loss: 0.1174 - acc: 0.9927 - val_loss: 1.1277 - val_acc: 0.8627\n",
      "612/612 [==============================] - 0s 190us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 4.8904 - acc: 0.6545 - val_loss: 5.6079 - val_acc: 0.6291\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 3.8793 - acc: 0.7406 - val_loss: 3.2071 - val_acc: 0.7794\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.6722 - acc: 0.8161 - val_loss: 2.3837 - val_acc: 0.8366\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.3907 - acc: 0.8348 - val_loss: 2.4263 - val_acc: 0.8317\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.1903 - acc: 0.8516 - val_loss: 2.6310 - val_acc: 0.8252\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.3599 - acc: 0.8434 - val_loss: 2.4451 - val_acc: 0.8333\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.3034 - acc: 0.8489 - val_loss: 2.3537 - val_acc: 0.8448\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.1522 - acc: 0.8598 - val_loss: 2.8068 - val_acc: 0.8105\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.6086 - acc: 0.8935 - val_loss: 2.3178 - val_acc: 0.8431\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.6842 - acc: 0.8876 - val_loss: 2.5794 - val_acc: 0.8252\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.8141 - acc: 0.8826 - val_loss: 2.6007 - val_acc: 0.8333\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.5607 - acc: 0.8990 - val_loss: 2.8162 - val_acc: 0.8186\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.5357 - acc: 0.8980 - val_loss: 2.2810 - val_acc: 0.8529\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.6080 - acc: 0.8958 - val_loss: 2.5720 - val_acc: 0.8366\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.5185 - acc: 0.9012 - val_loss: 2.0715 - val_acc: 0.8644\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.3151 - acc: 0.9135 - val_loss: 2.3780 - val_acc: 0.8497\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 2.0150 - acc: 0.8689 - val_loss: 2.8458 - val_acc: 0.8170\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.4412 - acc: 0.9062 - val_loss: 2.5241 - val_acc: 0.8350\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.3535 - acc: 0.9126 - val_loss: 2.6732 - val_acc: 0.8252\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.4189 - acc: 0.9094 - val_loss: 2.5027 - val_acc: 0.8350\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.5650 - acc: 0.8967 - val_loss: 2.5038 - val_acc: 0.8366\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.3668 - acc: 0.9112 - val_loss: 2.4893 - val_acc: 0.8399\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 1.5485 - acc: 0.9008 - val_loss: 2.9044 - val_acc: 0.8137\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.4688 - acc: 0.9044 - val_loss: 2.4261 - val_acc: 0.8431\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 1.2305 - acc: 0.9213 - val_loss: 2.7143 - val_acc: 0.8235\n",
      "612/612 [==============================] - 0s 156us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 4.6264 - acc: 0.6791 - val_loss: 2.8547 - val_acc: 0.7941\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.2879 - acc: 0.7833 - val_loss: 3.3544 - val_acc: 0.7794\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.3606 - acc: 0.7774 - val_loss: 3.5490 - val_acc: 0.7647\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.1874 - acc: 0.7915 - val_loss: 2.3629 - val_acc: 0.8448\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 2.8610 - acc: 0.8143 - val_loss: 2.7647 - val_acc: 0.8186\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 5s 2ms/step - loss: 2.5637 - acc: 0.8343 - val_loss: 3.8704 - val_acc: 0.7582\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.0415 - acc: 0.8070 - val_loss: 3.1223 - val_acc: 0.8023\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 2.6608 - acc: 0.8311 - val_loss: 3.9651 - val_acc: 0.7516\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.0019 - acc: 0.8097 - val_loss: 3.5117 - val_acc: 0.7761\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 2.4579 - acc: 0.8425 - val_loss: 3.0749 - val_acc: 0.8072\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.4319 - acc: 0.7843 - val_loss: 3.4307 - val_acc: 0.7810\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 5s 2ms/step - loss: 2.7523 - acc: 0.8257 - val_loss: 4.9415 - val_acc: 0.6912\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.9461 - acc: 0.7528 - val_loss: 3.1912 - val_acc: 0.7990\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 2.6348 - acc: 0.8348 - val_loss: 2.9433 - val_acc: 0.8137\n",
      "612/612 [==============================] - 0s 382us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 4.3303 - acc: 0.6263 - val_loss: 2.2955 - val_acc: 0.7908\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 2s 880us/step - loss: 2.3567 - acc: 0.7765 - val_loss: 1.9479 - val_acc: 0.8235\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 2s 891us/step - loss: 1.6677 - acc: 0.8243 - val_loss: 1.4139 - val_acc: 0.8562\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 2s 869us/step - loss: 1.2272 - acc: 0.8580 - val_loss: 1.2336 - val_acc: 0.8497\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 2s 971us/step - loss: 0.9411 - acc: 0.8762 - val_loss: 1.0158 - val_acc: 0.8709\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 2s 905us/step - loss: 0.7374 - acc: 0.8930 - val_loss: 1.2592 - val_acc: 0.8546\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 2s 907us/step - loss: 0.6431 - acc: 0.9053 - val_loss: 1.1362 - val_acc: 0.8546\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 2s 915us/step - loss: 0.5879 - acc: 0.9140 - val_loss: 1.1131 - val_acc: 0.8660\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 2s 921us/step - loss: 0.3853 - acc: 0.9372 - val_loss: 1.0831 - val_acc: 0.8578\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 2s 897us/step - loss: 0.4500 - acc: 0.9404 - val_loss: 1.1055 - val_acc: 0.8611\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 2s 873us/step - loss: 0.3465 - acc: 0.9472 - val_loss: 1.0932 - val_acc: 0.8464\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 2s 854us/step - loss: 0.3508 - acc: 0.9463 - val_loss: 1.1070 - val_acc: 0.8513\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 2s 944us/step - loss: 0.3230 - acc: 0.9504 - val_loss: 1.2178 - val_acc: 0.8546\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 2s 897us/step - loss: 0.3023 - acc: 0.9558 - val_loss: 1.0825 - val_acc: 0.8595\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 2s 874us/step - loss: 0.2744 - acc: 0.9563 - val_loss: 1.2625 - val_acc: 0.8578\n",
      "612/612 [==============================] - 0s 161us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 5.0087 - acc: 0.6395 - val_loss: 4.1635 - val_acc: 0.7092\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.7879 - acc: 0.7415 - val_loss: 3.1194 - val_acc: 0.7892\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.1823 - acc: 0.7838 - val_loss: 3.0637 - val_acc: 0.7892\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.9094 - acc: 0.8056 - val_loss: 2.9199 - val_acc: 0.7990\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.7710 - acc: 0.8161 - val_loss: 2.3671 - val_acc: 0.8448\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.4688 - acc: 0.8357 - val_loss: 2.7439 - val_acc: 0.8219\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.3500 - acc: 0.8443 - val_loss: 3.1529 - val_acc: 0.7925\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.4475 - acc: 0.8411 - val_loss: 2.3170 - val_acc: 0.8480\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.3884 - acc: 0.8439 - val_loss: 2.6384 - val_acc: 0.8268\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.3681 - acc: 0.8457 - val_loss: 2.4128 - val_acc: 0.8382\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.1127 - acc: 0.8607 - val_loss: 2.5378 - val_acc: 0.8301\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.3316 - acc: 0.8493 - val_loss: 3.0231 - val_acc: 0.8056\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 2.4126 - acc: 0.8462 - val_loss: 3.0303 - val_acc: 0.8056\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.2009 - acc: 0.8594 - val_loss: 2.7874 - val_acc: 0.8219\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.8277 - acc: 0.8817 - val_loss: 2.7494 - val_acc: 0.8268\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.8601 - acc: 0.8812 - val_loss: 2.2544 - val_acc: 0.8546\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.6945 - acc: 0.8926 - val_loss: 2.6475 - val_acc: 0.8317\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.8806 - acc: 0.8794 - val_loss: 2.4394 - val_acc: 0.8431\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.6909 - acc: 0.8917 - val_loss: 2.3554 - val_acc: 0.8497\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.0228 - acc: 0.8689 - val_loss: 2.6350 - val_acc: 0.8317\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.1261 - acc: 0.8644 - val_loss: 2.6116 - val_acc: 0.8350\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 1.8995 - acc: 0.8798 - val_loss: 2.3773 - val_acc: 0.8480\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.8044 - acc: 0.8862 - val_loss: 2.5411 - val_acc: 0.8366\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 1.8350 - acc: 0.8826 - val_loss: 2.8249 - val_acc: 0.8154\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.1197 - acc: 0.8657 - val_loss: 3.1947 - val_acc: 0.7990\n",
      "Epoch 26/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 1.9815 - acc: 0.8735 - val_loss: 2.4586 - val_acc: 0.8415\n",
      "612/612 [==============================] - 0s 215us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 8s 3ms/step - loss: 7.2696 - acc: 0.5239 - val_loss: 6.2262 - val_acc: 0.6062\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 6.3165 - acc: 0.6013 - val_loss: 7.8884 - val_acc: 0.5033\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 6.2370 - acc: 0.6063 - val_loss: 5.5517 - val_acc: 0.6536\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 6.1181 - acc: 0.6177 - val_loss: 6.0095 - val_acc: 0.6258\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 5.6383 - acc: 0.6477 - val_loss: 5.6787 - val_acc: 0.6454\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 5.6691 - acc: 0.6427 - val_loss: 6.3279 - val_acc: 0.6046\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 5s 2ms/step - loss: 6.1858 - acc: 0.6127 - val_loss: 6.4937 - val_acc: 0.5948\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 6.8215 - acc: 0.5744 - val_loss: 7.0428 - val_acc: 0.5605\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 6.4247 - acc: 0.5999 - val_loss: 7.4190 - val_acc: 0.5376\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 6.3049 - acc: 0.6063 - val_loss: 5.8336 - val_acc: 0.6373\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 6.3462 - acc: 0.6058 - val_loss: 6.5059 - val_acc: 0.5931\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 5.9969 - acc: 0.6272 - val_loss: 5.9091 - val_acc: 0.6324\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 6.3722 - acc: 0.6031 - val_loss: 6.1755 - val_acc: 0.6160\n",
      "612/612 [==============================] - 0s 327us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 3s 1ms/step - loss: 8.0724 - acc: 0.4392 - val_loss: 5.0416 - val_acc: 0.6487\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2197/2197 [==============================] - 2s 855us/step - loss: 6.3457 - acc: 0.5644 - val_loss: 2.7681 - val_acc: 0.7794\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 2s 873us/step - loss: 5.0902 - acc: 0.6431 - val_loss: 2.6652 - val_acc: 0.8072\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 2s 847us/step - loss: 4.1100 - acc: 0.7037 - val_loss: 2.7781 - val_acc: 0.7908\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 2s 849us/step - loss: 3.3621 - acc: 0.7483 - val_loss: 2.6436 - val_acc: 0.8137\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 2s 924us/step - loss: 3.1340 - acc: 0.7711 - val_loss: 2.3546 - val_acc: 0.8252\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 2s 850us/step - loss: 2.9991 - acc: 0.7833 - val_loss: 2.1734 - val_acc: 0.8333\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 2s 882us/step - loss: 2.5683 - acc: 0.8107 - val_loss: 1.8052 - val_acc: 0.8611\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 2s 806us/step - loss: 2.4676 - acc: 0.8193 - val_loss: 1.9228 - val_acc: 0.8578\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 2s 862us/step - loss: 2.2465 - acc: 0.8243 - val_loss: 1.8572 - val_acc: 0.8627\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 2s 831us/step - loss: 2.2195 - acc: 0.8257 - val_loss: 1.8678 - val_acc: 0.8627\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 2s 837us/step - loss: 2.0946 - acc: 0.8348 - val_loss: 1.8161 - val_acc: 0.8627\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 2s 852us/step - loss: 1.9796 - acc: 0.8348 - val_loss: 1.8161 - val_acc: 0.8546\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 2s 905us/step - loss: 1.7682 - acc: 0.8457 - val_loss: 1.6924 - val_acc: 0.8529\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 2s 888us/step - loss: 1.7623 - acc: 0.8462 - val_loss: 1.7123 - val_acc: 0.8578\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 2s 862us/step - loss: 1.5222 - acc: 0.8598 - val_loss: 1.5618 - val_acc: 0.8595\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 2s 874us/step - loss: 1.3787 - acc: 0.8553 - val_loss: 1.4376 - val_acc: 0.8562\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 2s 856us/step - loss: 1.2478 - acc: 0.8539 - val_loss: 1.1741 - val_acc: 0.8611\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 2s 867us/step - loss: 1.2061 - acc: 0.8439 - val_loss: 1.4335 - val_acc: 0.8301\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 2s 870us/step - loss: 1.1365 - acc: 0.8525 - val_loss: 1.3964 - val_acc: 0.8660\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 2s 885us/step - loss: 1.0815 - acc: 0.8671 - val_loss: 1.3648 - val_acc: 0.8611\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 2s 934us/step - loss: 0.8976 - acc: 0.8703 - val_loss: 1.4517 - val_acc: 0.8464\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 2s 981us/step - loss: 0.9132 - acc: 0.8712 - val_loss: 1.3426 - val_acc: 0.8464\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 2s 915us/step - loss: 0.8007 - acc: 0.8789 - val_loss: 1.4236 - val_acc: 0.8431\n",
      "Epoch 25/150\n",
      "2197/2197 [==============================] - 2s 835us/step - loss: 0.7950 - acc: 0.8789 - val_loss: 1.3510 - val_acc: 0.8415\n",
      "Epoch 26/150\n",
      "2197/2197 [==============================] - 2s 875us/step - loss: 0.7230 - acc: 0.8889 - val_loss: 1.3515 - val_acc: 0.8578\n",
      "Epoch 27/150\n",
      "2197/2197 [==============================] - 2s 861us/step - loss: 0.7840 - acc: 0.8830 - val_loss: 1.3150 - val_acc: 0.8562\n",
      "Epoch 28/150\n",
      "2197/2197 [==============================] - 2s 842us/step - loss: 0.6560 - acc: 0.8930 - val_loss: 1.3233 - val_acc: 0.8415\n",
      "612/612 [==============================] - 0s 158us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 5s 2ms/step - loss: 7.3810 - acc: 0.5011 - val_loss: 4.4707 - val_acc: 0.6879\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 5.5840 - acc: 0.6240 - val_loss: 3.1791 - val_acc: 0.7843\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 4.6970 - acc: 0.6937 - val_loss: 2.6045 - val_acc: 0.8219\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 4.0903 - acc: 0.7337 - val_loss: 2.6572 - val_acc: 0.8252\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 4.0513 - acc: 0.7346 - val_loss: 3.0875 - val_acc: 0.7974\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 3.9517 - acc: 0.7460 - val_loss: 3.1036 - val_acc: 0.8007\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 3.5039 - acc: 0.7715 - val_loss: 2.6810 - val_acc: 0.8284\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.3342 - acc: 0.7865 - val_loss: 2.3696 - val_acc: 0.8399\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.1129 - acc: 0.7993 - val_loss: 2.3845 - val_acc: 0.8480\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.2196 - acc: 0.7920 - val_loss: 2.7771 - val_acc: 0.8186\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.0483 - acc: 0.8025 - val_loss: 2.4726 - val_acc: 0.8399\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.1059 - acc: 0.8002 - val_loss: 2.3611 - val_acc: 0.8464\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.0260 - acc: 0.8043 - val_loss: 2.6142 - val_acc: 0.8284\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.0545 - acc: 0.8052 - val_loss: 2.3934 - val_acc: 0.8464\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 3.0630 - acc: 0.8043 - val_loss: 2.9461 - val_acc: 0.8137\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.0434 - acc: 0.8052 - val_loss: 2.5121 - val_acc: 0.8399\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.1736 - acc: 0.7979 - val_loss: 2.4359 - val_acc: 0.8464\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.0520 - acc: 0.8052 - val_loss: 3.4703 - val_acc: 0.7827\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 3.3582 - acc: 0.7865 - val_loss: 3.4870 - val_acc: 0.7778\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 4s 2ms/step - loss: 3.1349 - acc: 0.8020 - val_loss: 2.6003 - val_acc: 0.8366\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.7839 - acc: 0.8234 - val_loss: 2.5166 - val_acc: 0.8382\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 3s 2ms/step - loss: 2.5988 - acc: 0.8352 - val_loss: 2.6876 - val_acc: 0.8268\n",
      "612/612 [==============================] - 0s 190us/step\n",
      "Train on 2197 samples, validate on 612 samples\n",
      "Epoch 1/150\n",
      "2197/2197 [==============================] - 8s 4ms/step - loss: 7.2413 - acc: 0.5139 - val_loss: 5.2232 - val_acc: 0.6585\n",
      "Epoch 2/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 4.8561 - acc: 0.6755 - val_loss: 5.1292 - val_acc: 0.6650\n",
      "Epoch 3/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 4.9320 - acc: 0.6796 - val_loss: 3.4071 - val_acc: 0.7761\n",
      "Epoch 4/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 4.2906 - acc: 0.7251 - val_loss: 3.5873 - val_acc: 0.7696\n",
      "Epoch 5/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.7781 - acc: 0.7588 - val_loss: 2.6565 - val_acc: 0.8284\n",
      "Epoch 6/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 4.2444 - acc: 0.7319 - val_loss: 4.4423 - val_acc: 0.7190\n",
      "Epoch 7/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 4.0467 - acc: 0.7419 - val_loss: 3.4000 - val_acc: 0.7827\n",
      "Epoch 8/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 4.0725 - acc: 0.7383 - val_loss: 3.8990 - val_acc: 0.7516\n",
      "Epoch 9/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.5982 - acc: 0.7697 - val_loss: 3.6870 - val_acc: 0.7696\n",
      "Epoch 10/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.6337 - acc: 0.7701 - val_loss: 2.9660 - val_acc: 0.8137\n",
      "Epoch 11/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 3.3228 - acc: 0.7893 - val_loss: 3.8593 - val_acc: 0.7582\n",
      "Epoch 12/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.7128 - acc: 0.7656 - val_loss: 4.1869 - val_acc: 0.7386\n",
      "Epoch 13/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 5.0197 - acc: 0.6846 - val_loss: 7.5903 - val_acc: 0.5278\n",
      "Epoch 14/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 4.0574 - acc: 0.7447 - val_loss: 2.6342 - val_acc: 0.8317\n",
      "Epoch 15/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.1239 - acc: 0.8015 - val_loss: 3.3270 - val_acc: 0.7925\n",
      "Epoch 16/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 3.4359 - acc: 0.7852 - val_loss: 2.9537 - val_acc: 0.8121\n",
      "Epoch 17/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.1270 - acc: 0.8047 - val_loss: 3.3036 - val_acc: 0.7925\n",
      "Epoch 18/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.0723 - acc: 0.8079 - val_loss: 3.1483 - val_acc: 0.8007\n",
      "Epoch 19/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 4.5190 - acc: 0.7169 - val_loss: 4.6765 - val_acc: 0.7092\n",
      "Epoch 20/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 4.1117 - acc: 0.7437 - val_loss: 3.2811 - val_acc: 0.7925\n",
      "Epoch 21/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 3.4720 - acc: 0.7829 - val_loss: 4.2358 - val_acc: 0.7369\n",
      "Epoch 22/150\n",
      "2197/2197 [==============================] - 6s 3ms/step - loss: 3.7627 - acc: 0.7647 - val_loss: 5.2237 - val_acc: 0.6748\n",
      "Epoch 23/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 4.6480 - acc: 0.7105 - val_loss: 3.7940 - val_acc: 0.7631\n",
      "Epoch 24/150\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 3.4094 - acc: 0.7865 - val_loss: 4.9629 - val_acc: 0.6895\n",
      "612/612 [==============================] - 0s 297us/step\n"
     ]
    }
   ],
   "source": [
    "#apply grid-search-like loops to try multiple combinations of hyperparameters\n",
    "for drop_out in [0,0.25,0.5]:\n",
    "    for nb_neurons in [128,256,512]:\n",
    "        #create model\n",
    "        model = create_model2(nb_neurons, drop_out)\n",
    "        #apply early_stopping to prevent overfitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "        #train the model\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                            epochs=150,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_data=(validation_data, validation_labels),\n",
    "                            callbacks=[early_stopping]\n",
    "                            )\n",
    "        #evaluate model on the validation set\n",
    "        result = model.evaluate(validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "        Result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers Drop Out  Neurons Accuracy\n",
      "1 &  0.00 & 128 & 84.477 \\\\\n",
      "\\hline\n",
      "1 &  0.00 & 256 & 67.647 \\\\\n",
      "\\hline\n",
      "1 &  0.00 & 512 & 49.673 \\\\\n",
      "\\hline\n",
      "1 &  0.25 & 128 & 84.150 \\\\\n",
      "\\hline\n",
      "1 &  0.25 & 256 & 86.438 \\\\\n",
      "\\hline\n",
      "1 &  0.25 & 512 & 67.157 \\\\\n",
      "\\hline\n",
      "1 &  0.50 & 128 & 87.418 \\\\\n",
      "\\hline\n",
      "1 &  0.50 & 256 & 87.255 \\\\\n",
      "\\hline\n",
      "1 &  0.50 & 512 & 83.333 \\\\\n",
      "\\hline\n",
      "2 &  0.00 & 128 & 86.275 \\\\\n",
      "\\hline\n",
      "2 &  0.00 & 256 & 82.353 \\\\\n",
      "\\hline\n",
      "2 &  0.00 & 512 & 81.373 \\\\\n",
      "\\hline\n",
      "2 &  0.25 & 128 & 85.784 \\\\\n",
      "\\hline\n",
      "2 &  0.25 & 256 & 84.150 \\\\\n",
      "\\hline\n",
      "2 &  0.25 & 512 & 61.601 \\\\\n",
      "\\hline\n",
      "2 &  0.50 & 128 & 84.150 \\\\\n",
      "\\hline\n",
      "2 &  0.50 & 256 & 82.680 \\\\\n",
      "\\hline\n",
      "2 &  0.50 & 512 & 68.954 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "#show the results in table-like format\n",
    "i = 0\n",
    "print('Layers ' +'Drop Out ' + ' Neurons ' + 'Accuracy')\n",
    "for nb_layers in [1,2]:\n",
    "    for drop_out in [0,0.25,0.5]:\n",
    "        for nb_neurons in [128,256,512]:\n",
    "            print( '%1d & %5.2f & %3d & %5.3f \\\\\\\\' % (nb_layers ,drop_out,nb_neurons,Result[i][1]*100))\n",
    "            print('\\hline')\n",
    "            i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
